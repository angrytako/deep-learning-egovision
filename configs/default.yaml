action: train # train or test OR save IN CASE OF "save_feat"
name: SVM-train # name of the experiment needed for the logs
#name: LSTM-train # name of the experiment needed for the logs
modality: ["RGB"] # modality used; needs to be specified in the model section as well; also used to store and retrieve extracted
#features; IT ALSO HAS TO BE SET UNDER "DATASET" SO IT CAN SAVE/LOAD FEATURES OR INITIAL ACTUAL DATASET
total_batch: 128 # total batch size if training is done with gradient accumulation
batch_size: 32 # batch size for the forward
gpus: null # gpus adopted
wandb_name: null # needed for wandb logging
resume_from: null # checkpoint directory | NEEDS TO BE SET FOR TRAINING/VALIDATION BUT ALSO FOR SAVING CHECKPOINTS
logname: null # name of the logs
models_dir: null # directory containing all the models
need_clips: False # for lstm true

train: #THE SPECIFIC VALUES OF THE LEARNING IS IN THE MODELS SECTION!!!
  num_iter: 5000 # number of training iterations with total_batch size
  lr_steps: 3000 # steps before reducing learning rate
  eval_freq: 50 # evaluation frequency
  num_clips: 5 # clips adopted in training
  dense_sampling: # sampling version adopted in training for each modality
    RGB: False
  num_frames_per_clip: # number of frames adopted in training for each modality
    RGB: 15

test:
  num_clips: 5 # number of clips in testing
  dense_sampling: # sampling version adopted in test for each modality
    RGB: False
  num_frames_per_clip: # number of frames adopted in test for each modality
    RGB: 15

dataset:
  annotations_path: train_val # path for the annotations data
  shift: D2-D2 # shifts of the dataset ; is "split" in EPICKitchenDataloader and is [D1,D2,D3]; when train + val [train_split - val_split]
  #for validation the test split will be used; THIS IS USED ALSO FOR SAVING THE FEATURES!!
  workers: 4 # number of workers for the dataloader
  stride: 2 # stride in case of dense sampling
  resolution: 224 # input resolution to the model
  RGB:
    data_path: ./extracted_features/ # path to RGB data
    tmpl: "img_{:010d}.jpg" # format of RGB filenames
    features_name: features_D2_uniform_15
  Event: # not neeeded for the project
    rgb4e: 6

# these are the action recognition models for each modality
models:
  RGB:
    model: Classifier # Name of the ACTUAL class used in training/testing or saving checkpoints. It needs to be imported in __init__.py
    #model: LSTM
    normalize: False
    kwargs: {}
    lr_steps: 3000
    lr: 0.01
    sgd_momentum: 0.9
    weight_decay: 1e-7
    #added to give information abount the model dynamically
    n_features: 1024
    hidden_size: 128 #needed only for LSTM
    num_layers: 3
