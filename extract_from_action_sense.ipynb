{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_FRAMERATE = 0.5 #nr of frames per second\n",
    "#it takes my pc 3 min 15 s with framerate 0.5. For 25 fps, estimated is 2 h and 45 mins\n",
    "PATH_TO_VIDEO = '2022-06-14_16-38-43_S04_eye-tracking-video-world_frame.mp4'\n",
    "PATH_TO_INFO_AND_CROSS = \"2022-06-14_16-38-43_streamLog_actionNet-wearables_S04.hdf5\"\n",
    "VIDEO_ID = \"S04_01\"\n",
    "FRAMES_SAVE_PATH = \"actionNet/\" + VIDEO_ID\n",
    "CALIBRATION_SHIFT = 14*60 + 21 # the first part of the video is usless\n",
    "\n",
    "VIDEO_SAMPLING_RATE = 1/VIDEO_FRAMERATE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video transformation into frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(FRAMES_SAVE_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def transform_to_frames(frameRate, path_to_video, frames_save_path, shift=0): \n",
    "    vidcap = cv2.VideoCapture(path_to_video)\n",
    "    def getFrame(sec):\n",
    "        vidcap.set(cv2.CAP_PROP_POS_MSEC,sec*1000)\n",
    "        hasFrames,image = vidcap.read()\n",
    "        if hasFrames:\n",
    "            cv2.imwrite(frames_save_path+\"/img_\"+f'{count:010d}'+\".jpg\", image)     # save frame as JPG file\n",
    "        return hasFrames\n",
    "    sec = 0\n",
    "    count=0\n",
    "    success = getFrame(sec)\n",
    "    while success:\n",
    "        count = count + 1\n",
    "        sec = sec + frameRate\n",
    "        sec = round(sec, 2)\n",
    "        success = getFrame(sec+shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_to_frames(VIDEO_SAMPLING_RATE, PATH_TO_VIDEO, FRAMES_SAVE_PATH,CALIBRATION_SHIFT)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels and dataframe (records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py, numpy as np\n",
    "\n",
    "\n",
    "h5_file = h5py.File(PATH_TO_INFO_AND_CROSS)\n",
    "\n",
    "device_name = 'experiment-activities'\n",
    "stream_name = 'activities'\n",
    "\n",
    "# Get the timestamped label data.\n",
    "# As described in the HDF5 metadata, each row has entries for ['Activity', 'Start/Stop', 'Valid', 'Notes'].\n",
    "activity_datas = h5_file[device_name][stream_name]['data']\n",
    "activity_times_s = h5_file[device_name][stream_name]['time_s']\n",
    "activity_times_s = np.squeeze(np.array(activity_times_s))  # squeeze (optional) converts from a list of single-element lists to a 1D list\n",
    "# Convert to strings for convenience.\n",
    "activity_datas = [[x.decode('utf-8') for x in datas] for datas in activity_datas]\n",
    "\n",
    "# Combine start/stop rows to single activity entries with start/stop times.\n",
    "#   Each row is either the start or stop of the label.\n",
    "#   The notes and ratings fields are the same for the start/stop rows of the label, so only need to check one.\n",
    "exclude_bad_labels = True # some activities may have been marked as 'Bad' or 'Maybe' by the experimenter; submitted notes with the activity typically give more information\n",
    "activities_labels = []\n",
    "activities_start_times_s = []\n",
    "activities_end_times_s = []\n",
    "activities_ratings = []\n",
    "activities_notes = []\n",
    "for (row_index, time_s) in enumerate(activity_times_s):\n",
    "  label    = activity_datas[row_index][0]\n",
    "  is_start = activity_datas[row_index][1] == 'Start'\n",
    "  is_stop  = activity_datas[row_index][1] == 'Stop'\n",
    "  rating   = activity_datas[row_index][2]\n",
    "  notes    = activity_datas[row_index][3]\n",
    "  if exclude_bad_labels and rating in ['Bad', 'Maybe']:\n",
    "    continue\n",
    "  # Record the start of a new activity.\n",
    "  if is_start:\n",
    "    activities_labels.append(label)\n",
    "    activities_start_times_s.append(time_s)\n",
    "    activities_ratings.append(rating)\n",
    "    activities_notes.append(notes)\n",
    "  # Record the end of the previous activity.\n",
    "  if is_stop:\n",
    "    activities_end_times_s.append(time_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "action_net = pd.read_pickle(\"./action-net/ActionNet_train.pkl\")\n",
    "action_dict = {}\n",
    "for i,row in action_net[[\"description\", \"labels\"]].iterrows():\n",
    "    desc = row[0]\n",
    "    label = row[1]\n",
    "    action_dict[desc] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = {}\n",
    "i=0\n",
    "for label in set(action_net[\"labels\"]):\n",
    "    labels_dict[label] = i\n",
    "    i+=1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'Clean',\n",
    " 'Clear',\n",
    " 'Get/Put',\n",
    " 'Load',\n",
    " 'Open/Close',\n",
    " 'Peel',\n",
    " 'Pour',\n",
    " 'Set',\n",
    " 'Slice',\n",
    " 'Spread',\n",
    " 'Stack',\n",
    " 'Unload'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO decide if we want to merge the same actions into one\n",
    "#TODO reduce to only actions\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "#seeding uuid \n",
    "import uuid\n",
    "import random\n",
    "rd = random.Random()\n",
    "rd.seed(9341)\n",
    "\n",
    "#\"start_timestamp\", \"stop_timestamp\"\n",
    "records = []\n",
    "shift = datetime.utcfromtimestamp(min(activities_start_times_s))\n",
    "for i, label in enumerate(activities_labels) :\n",
    "    #activities_end_times_s\n",
    "    #start_timestamp = datetime.timestamp(datetime.utcfromtimestamp(activities_start_times_s[i]) - shift)\n",
    "    #stop_timestamp = datetime.timestamp(datetime.utcfromtimestamp(activities_end_times_s[i]) - shift)\n",
    "    start_frame = int((datetime.utcfromtimestamp(activities_start_times_s[i]) - shift).total_seconds() * VIDEO_FRAMERATE)\n",
    "    stop_frame = int((datetime.utcfromtimestamp(activities_end_times_s[i]) - shift).total_seconds() * VIDEO_FRAMERATE)\n",
    "    narration = label\n",
    "    verb = action_dict[label]\n",
    "    verb_class = labels_dict[verb]\n",
    "    uuid_str = uuid.UUID(int=rd.getrandbits(128))\n",
    "    records.append([uuid_str, VIDEO_ID, start_frame,stop_frame, narration, verb, verb_class])\n",
    "\n",
    "records_pd = pd.DataFrame(records,columns=[\"uuid\", \"video_id\",\"start_frame\", \"stop_frame\", \"narration\", \"verb\", \"verb_class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO save as pkl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
